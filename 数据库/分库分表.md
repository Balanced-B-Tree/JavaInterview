[toc]



[聊聊分库分表 (qq.com)](https://mp.weixin.qq.com/s/VZXunsXEWAdRr3bup7L9yA)

# 瓶颈

## IO瓶颈

第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -> 分库和垂直分表。

第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -> 分库。



## CPU瓶颈

**第一种**：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作 -> SQL优化，建立合适的索引，在业务Service层进行业务计算。

**第二种**：单表数据量太大，查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈 -> 水平分表。



# 分表

## 水平分表

IO未瓶颈，CPU瓶颈了

**场景：**系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。

**分析：**表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。



## 垂直分表

表内存在大量非热点数据的列，使得每次IO得到的有效数据较少

**场景：**系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，**单行数据所需的存储空间较大。以至于数据库缓存的数据行减少**，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。



分表：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是**将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。**这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。

但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。**关联数据，应该在业务Service层做文章**，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。



# 分库

## 水平分库

网络IO瓶颈

**分析：**库多了，io和cpu的压力自然可以成倍缓解。



## 垂直分库



# 新库与旧库

不停服的时候，应该怎么做呢，分五个步骤：

1. 编写代理层，加个开关（控制访问新的DAO还是老的DAO，或者是都访问），灰度期间，还是访问老的DAO。
2. 发版全量后，开启双写，既在旧表新增和修改，也在新表新增和修改。日志或者临时表记下新表ID起始值，旧表中小于这个值的数据就是存量数据，这批数据就是要迁移的。
3. 通过脚本把旧表的存量数据写入新表。
4. **停读旧表改读新表**，此时新表已经承载了所有读写业务，但是这时候不要立刻停写旧表，需要保持双写一段时间。
5. 当读写新表一段时间之后，如果没有业务问题，就可以**停写旧表**啦



## 非停机迁移

[数据库迁移_SoWhat1412的博客-CSDN博客](https://blog.csdn.net/qq_31821675/article/details/89465597)



**历史数据**:在该次部署前，数据库表test_tb的有关数据，我们称之为历史数据。

**增量数据**:在该次部署后，数据库表test_tb的新产生的数据，我们称之为增量数据。

这个时间点，可以用一个递增的 key来区分，称为 max。



迁移流程如下

1. 先迁移历史数据。即 test_tb_old表里，主键小等于 max（新旧数据的分界点）的值
2. 再迁移增量数据。
   1. 将 max后对 test_tb的 update、delete、insert等修改操作发送到消息队列里。（==这里会对原有的业务造成代码入侵，因为需要发送消息的代码==，可以使用订阅 binlog来避免代码入侵）
   2. 等历史数据迁移完毕，就开始消费队列里的增量数据
3. 新老数据库进行一致性验证
   1. 验数量是否一致，因为验数量比较快。
   2. 或者只验关键性的几个字段是否一致。
   3. 或者一次取50条(不一定50条，具体自己定，我只是举例),然后像拼字符串一样，拼在一起。用md5进行加密，得到一串数值。新库一样如法炮制，也得到一串数值，比较两串数值是否一致。如果不一致，可以用二分的方式，找出不一致数据



# canal订阅binlog

[实战！Spring Boot 整合 阿里开源中间件 Canal 实现数据增量同步！ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&mid=2247503534&idx=1&sn=415d5031e125d9034df1da5aa61623aa&chksm=fcf71163cb809875a3df006f24991e5a6d657d1740a62955c9e3f0423cc7863bc652bd3c9d7f&token=688638199&lang=zh_CN&scene=21#wechat_redirect)

![preview](%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.assets/v2-b5bcf1767ce81e5ecf017507d0809b39_r.jpg)

## MySQL主备复制原理

![img](%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.assets/687474703a2f2f646c2e69746579652e636f6d2f75706c6f61642f6174746163686d656e742f303038302f333038362f34363863316131342d653761642d333239302d396433642d3434616335303161373232372e6a7067.jpeg)

- MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看)
- MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log)
- MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据



## canal 工作原理

- canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议
- MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )
- canal 解析 binary log 对象(原始为 byte 流)



# 分库分表可能遇到的问题



- 事务问题：需要用分布式事务啦
- 跨节点Join的问题：解决这一问题可以分两次查询实现。在server端实现 join
- 跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。
- 数据迁移，容量规划，扩容等问题
- ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID
- 跨分片的排序分页问题（后台加大pagesize处理？）





# mysql为什么单表最多两千万条数据

[mysql单表最多两千万条数据？ (qq.com)](https://mp.weixin.qq.com/s/-qZKwB8YKb_bOgWFfqsytg)

假设我们有这么一张user数据表。

![图片](%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.assets/640.png)

而上面user表数据，在硬盘上其实也是类似，放在了user.**ibd**文件下。含义是user表的innodb data文件，专业点，又叫**表空间**。

虽然在数据表里，它们看起来是挨在一起的。但实际上在user.ibd里他们被分成很多小份的**数据页**，每份大小16k。

为了唯一标识具体是哪一页，那就需要引入**页号**（其实是一个表空间的地址偏移量）。同时为了把这些数据页给关联起来，于是引入了**前后指针**，用于指向前后的页。这些都被加到了**页头**里。

页是需要读写的，16k说小也不小，写一半电源线被拔了也是有可能发生的，所以为了保证数据页的正确性，还引入了校验码。这个被加到了**页尾**。

那剩下的空间，才是用来放我们的record的。而record如果行数特别多的话，进入到页内时挨个遍历，效率也不太行，所以为这些数据生成了一个**页目录**，具体实现细节不重要。只需要知道，它可以通过**二分查找**的方式将查找效率**从O(n) 变成O(lgn)**。

![图片](%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.assets/640-20220407193641586.png)

## 页

[Mysql--InnoDB数据页结构 - 简书 (jianshu.com)](https://www.jianshu.com/p/0f268a0e1bc2)

1. 页是innodb管理存储空间的基本单位
2. 一般大小是16kb
3. 不同的页存储不同的数据类型，比如存放表空间头部信息的页，存放insertBuffer信息的页面，存放INODE的页，存放undo日志信息或者索引页（数据页）



## B+树承载的记录数量

一个16k的页，非叶子节点里每一条数据都指向一个新的页，而新的页有两种可能：

- 如果是末级叶子节点的话，那么里面放的就是一行行record数据。
- 如果是非叶子节点，那么就会循环继续指向新的数据页。

假设

- 非叶子结点内指向其他内存页的指针数量为`x`。B+树非叶子节点内，key的数量，大概能有1300个
- 叶子节点内能容纳的 row数量为`y`。一般15个以上
- B+树的层数为`z`。一般最高三层

那这棵B+树放的**行数据总量**等于 `(x^(z-1))*y = 2.5kw`。如果 row再小一些，比如只占256byte，那么单表可达一亿





